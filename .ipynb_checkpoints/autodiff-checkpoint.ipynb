{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deklaracja liczb dualnych\n",
    "struct Dual{T <:Number} <:Number\n",
    "    v::T\n",
    "    dv::T\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przeciazenie operatorow\n",
    "import Base: +, -, *, /\n",
    "-(x::Dual) = Dual(-x.v, -x.dv)\n",
    "+(x::Dual, y::Dual) = Dual( x.v + y.v, x.dv + y.dv)\n",
    "-(x::Dual, y::Dual) = Dual( x.v - y.v, x.dv - y.dv)\n",
    "*(x::Dual, y::Dual) = Dual( x.v * y.v, x.dv * y.v + x.v * y.dv)\n",
    "/(x::Dual, y::Dual) = Dual( x.v / y.v,(x.dv * y.v - x.v * y.dv)/y.v^2)\n",
    "# Przeciazenie funkcji\n",
    "import Base: abs, sin, cos, tan, exp, sqrt\n",
    "abs(x::Dual) = Dual(abs(x.v), sign(x.v)*x.dv)\n",
    "sin(x::Dual) = Dual(sin(x.v), cos(x.v)*x.dv)\n",
    "cos(x::Dual) = Dual(cos(x.v), -sin(x.v)*x.dv)\n",
    "tan(x::Dual) = Dual(tan(x.v), one(x.v)*x.dv + tan(x.v)^2*x.dv)\n",
    "exp(x::Dual) = Dual(exp(x.v), exp(x.v)*x.dv)\n",
    "sqrt(x::Dual) = Dual(sqrt(x.v), .5/sqrt(x.v) * x.dv)\n",
    "isless(x::Dual, y::Dual) = x.v < y.v;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetlanie liczb dualnych '(v) + [dv epsilon]'\n",
    "import Base: show\n",
    "show(io::IO, x::Dual) = print(io, \"(\", x.v, \") + [\", x.dv, \"ε]\");\n",
    "\n",
    "value(x::Dual) = x.v;\n",
    "partials(x::Dual) = x.dv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "promote_rule (generic function with 126 methods)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import Base: convert, promote_rule\n",
    "convert(::Type{Dual{T}}, x::Dual) where T = Dual(convert(T, x.v), convert(T, x.dv))\n",
    "convert(::Type{Dual{T}}, x::Number) where T = Dual(convert(T, x), zero(T))\n",
    "promote_rule(::Type{Dual{T}}, ::Type{R}) where {T,R} =  Dual{promote_type(T,R)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0) + [1ε]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ϵ = Dual(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0) + [1.0ε]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6.0 + ϵ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = sin(x*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0) + [0.0ε]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(Dual(1,1))\n",
    "zero(f(Dual(1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU (generic function with 1 method)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU(x) = max(zero(x), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jacobian_forward (generic function with 1 method)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_forward = function jacobian_forward(f, args::Vector{T}) where {T <:Number}\n",
    "    jacobian_columns = Matrix{T}[]\n",
    "    \n",
    "    for i=1:length(args)\n",
    "        x = Dual{T}[]\n",
    "        for j=1:length(args)\n",
    "            seed = (i == j)\n",
    "            push!(x, seed ?\n",
    "                Dual(args[j], one(args[j])) :\n",
    "                Dual(args[j],zero(args[j])) )\n",
    "        end\n",
    "        column = partials.([f(x)...])\n",
    "        push!(jacobian_columns, column[:,:])\n",
    "    end\n",
    "    hcat(jacobian_columns...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 2 methods)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x::Vector) = [sin(x[1]*x[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×2 Matrix{Float64}:\n",
       " 1.63233  2.04041"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_forward(f, [5.0,4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = x^3\n",
    "f′(x) = derivative(f,  x)\n",
    "f″(x) = derivative(f′, x)\n",
    "f‴(x) = derivative(f″, x)\n",
    "\n",
    "f(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @benchmark not defined\nin expression starting at In[81]:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @benchmark not defined\nin expression starting at In[81]:1",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "@benchmark D(f,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## backwards  https://web.archive.org/web/20200615205643/http://blog.rogerluo.me/2018/10/23/write-an-ad-in-one-day/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type Node end\n",
    "abstract type Operator end\n",
    "abstract type LeafNode <: Node end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Variable{T} <: LeafNode\n",
    "    value::T\n",
    "    grad::T\n",
    "    Variable(val::T) where T          = new{T}(val, zero(val))\n",
    "    Variable(val::T, grad::T) where T = new{T}(val, grad)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Method{OT} <: Operator\n",
    "    f::OT\n",
    "end\n",
    "\n",
    "struct Broadcasted{OT} <: Operator\n",
    "    f::OT\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComputableNode"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct ComputableNode{OT <: Operator, AT <: Tuple, KT <: NamedTuple} <: Node\n",
    "    op::OT\n",
    "    args::AT\n",
    "    kwargs::KT\n",
    "end\n",
    "ComputableNode(op::Function, args, kwargs) = ComputableNode(Method(op), args, kwargs)\n",
    "ComputableNode(op, args)                   = ComputableNode(op, args, NamedTuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CachedNode"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct CachedNode{NT <: Node, OUT} <: Node\n",
    "    node::NT\n",
    "    out::OUT\n",
    "end\n",
    "\n",
    "function CachedNode(op, args...; kwargs...)\n",
    "    node = ComputableNode(op, args, kwargs.data)\n",
    "    out  = forward(node)\n",
    "    CachedNode(node, out)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operator (generic function with 2 methods)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg(x::ComputableNode, i::Int) = x.args[i]\n",
    "args(x::ComputableNode) = x.args\n",
    "kwargs(x::ComputableNode) = x.kwargs\n",
    "operator(x::ComputableNode) = x.f\n",
    "\n",
    "arg(x::CachedNode, i::Int) = x.node.args[i]\n",
    "args(x::CachedNode) = x.node.args\n",
    "kwargs(x::CachedNode) = x.node.kwargs\n",
    "operator(x::CachedNode) = x.node.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base: show\n",
    "show(io::IO, x::Method)         = print(io, \"fn \",  x.f);\n",
    "show(io::IO, x::Operator)       = print(io, \"op \",  x.f);\n",
    "show(io::IO, x::Variable)       = print(io, \"var \", x.value);\n",
    "show(io::IO, x::CachedNode)     = print(io, \"{cached (\", x.node, \") => \", x.out, \"}\");\n",
    "show(io::IO, x::ComputableNode) = print(io, \"[\", x.op, \"](\", x.args, \")\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward (generic function with 7 methods)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(x) = x\n",
    "forward(leaf::LeafNode) = value(leaf)\n",
    "forward(node::ComputableNode) = forward(node.op, map(forward, node.args)...; map(forward, node.kwargs)...)\n",
    "forward(cached::CachedNode) = (cached.out = forward(cached.node))\n",
    "forward(op::Broadcasted, args...) = Broadcast.broadcasted(op.f, args...)\n",
    "forward(op::Operator, args...; kwargs...) = op.f(args...; kwargs...)\n",
    "forward(x::NT) where {NT <: Node} = error(\"forward method is not implemented for node type: $NT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value (generic function with 5 methods)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value(x) = x\n",
    "value(x::Variable) = x.value\n",
    "value(x::CachedNode) = value(x.out)\n",
    "value(x::T) where {T <: Node} = error(\"Expected value in this node $x of type $T\n",
    " check if you defined a non-cached node\n",
    " or overload value function for your node.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 7 methods)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backward(x::Variable, grad)\n",
    "    if isdefined(x, :grad)\n",
    "        x.grad+= grad\n",
    "    else\n",
    "        x.grad = grad\n",
    "    end\n",
    "    nothing\n",
    "end\n",
    "\n",
    "function backward(node::CachedNode, f, grad)\n",
    "    grad_inputs = gradient(node, grad)\n",
    "    for (each, each_grad) in zip(args(node), grad_inputs)\n",
    "        backward(each, each_grad)\n",
    "    end\n",
    "    nothing\n",
    "end\n",
    "\n",
    "function backward(cached::CachedNode, op::Broadcasted, grad)\n",
    "    grad_inputs = gradient(cached, grad)\n",
    "    for (each, each_grad) in zip(args(cached), grad_inputs)\n",
    "        backward(each, each_grad)\n",
    "    end\n",
    "    nothing\n",
    "end\n",
    "\n",
    "backward(cached::CachedNode) = backward(cached, 1.0)\n",
    "backward(cached::CachedNode, grad) = backward(cached, cached.node.op, grad)\n",
    "backward(cached::CachedNode, op::Method, grad) = backward(cached, op.f, grad)\n",
    "backward(cached::CachedNode, ::typeof(Broadcast.materialize), grad) = backward(arg(cached, 1), grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient (generic function with 28 methods)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(x::CachedNode, grad) = gradient(x.node.op, grad, x.out, map(value, x.node.args)...; map(value, x.node.kwargs)...)\n",
    "gradient(x::Operator,   grad, out, args...; kwargs...) = gradient(x.f, grad, out, args...; kwargs...)\n",
    "gradient(op, grad, out, args...; kwargs...) = error(\"gradient of operator $op is not defined\\n\n",
    " Possible Fix:\\n\n",
    " define one of the following:\\n\n",
    " 1. gradient(::typeof($op), grad, out, args...; kwargs...)\\n\n",
    " 2. gradient(op::Method{typeof($op)}, grad, out, args...; kwargs...)\\n\n",
    " 3. gradient(op::Broadcasted{typeof($op)}, grad, out, args...; kwargs...)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient (generic function with 28 methods)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: +, -, *, /\n",
    "+(x::Node) = CachedNode(+, x)\n",
    "-(x::Node) = CachedNode(-, x)\n",
    "gradient(::typeof(+), grad, output, x) = (grad * 1, )\n",
    "gradient(::typeof(-), grad, output, x) = (grad *-1, )\n",
    "+(x::Node, y::Node) = CachedNode(+, x, y)\n",
    "-(x::Node, y::Node) = CachedNode(-, x, y)\n",
    "*(x::Node, y::Node) = CachedNode(*, x, y)\n",
    "/(x::Node, y::Node) = CachedNode(/, x, y)\n",
    "gradient(::typeof(+), grad, output, x, y) = (grad * one(x),   grad * one(y))\n",
    "gradient(::typeof(-), grad, output, x, y) = (grad * one(x),   grad *-one(y))\n",
    "gradient(::typeof(*), grad, output, x, y) = (grad * y,        grad * x)\n",
    "gradient(::typeof(/), grad, output, x, y) = (grad * one(x)/y, grad *-x/y/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient (generic function with 28 methods)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: abs, sin, cos, tan, exp, sqrt, zero, iterate, length, isless\n",
    "abs(x::Node)  = CachedNode(abs, x)\n",
    "sin(x::Node)  = CachedNode(sin, x)\n",
    "cos(x::Node)  = CachedNode(cos, x)\n",
    "tan(x::Node)  = CachedNode(tan, x)\n",
    "exp(x::Node)  = CachedNode(exp, x)\n",
    "sqrt(x::Node) = CachedNode(sqrt, x)\n",
    "zero(x::Node) = CachedNode(zero, x)\n",
    "iterate(x::Node) = CachedNode(iterate, x)\n",
    "length(x::Node) = CachedNode(length, x)\n",
    "isless(x::Node, y::Node) = isless(value(x), value(y))\n",
    "gradient(::typeof(abs), grad, output, x)  = (grad * sign(x), )\n",
    "gradient(::typeof(sin), grad, output, x)  = (grad * cos(x), )\n",
    "gradient(::typeof(cos), grad, output, x)  = (grad *-sin(x), )\n",
    "gradient(::typeof(tan), grad, output, x)  = (grad *(tan(x)^2 + 1), )\n",
    "gradient(::typeof(exp), grad, output, x)  = (grad * exp(x), )\n",
    "gradient(::typeof(sqrt), grad, output, x) = (grad * 0.5/sqrt(x), )\n",
    "gradient(::typeof(zero), grad, output, x) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "promote_rule (generic function with 126 methods)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: convert, promote_rule\n",
    "convert(::Type{Variable{T}}, x::Number) where T   = Variable(convert(T, x))\n",
    "convert(::Type{Variable{T}}, x::Variable) where T = Variable(convert(T, x.value), convert(T, x.grad))\n",
    "promote_rule(::Type{Variable{T}}, ::Type{R}) where {T,R} = Variable{promote_type(R,T)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct ComputGraphStyle <: Broadcast.BroadcastStyle end\n",
    "Base.BroadcastStyle(::Type{<:Node}) = ComputGraphStyle()\n",
    "Broadcast.BroadcastStyle(s::ComputGraphStyle, x::Broadcast.BroadcastStyle) = s\n",
    "Broadcast.broadcasted(::ComputGraphStyle, f, args...) = CachedNode(Broadcasted(f), args...)\n",
    "Broadcast.broadcastable(x::Node) = x\n",
    "Broadcast.materialize(x::Node) = CachedNode(Broadcast.materialize, x)\n",
    "Base.similar(x::Node)                                      = Variable(similar(value(x)))\n",
    "Base.similar(x::Node, dims::Dims)                          = Variable(similar(value(x), dims))\n",
    "Base.similar(x::Node, eltype::Type{S}, dims::Dims) where S = Variable(similar(value(x), eltype, dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient (generic function with 28 methods)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(::Broadcasted{typeof(+)}, grad, output, x)    = @. (grad * 1, )\n",
    "gradient(::Broadcasted{typeof(-)}, grad, output, x)    = @. (grad *-1, )\n",
    "gradient(::Broadcasted{typeof(+)}, grad, output, x, y) = @. (grad * one(x),   grad * one(y))\n",
    "gradient(::Broadcasted{typeof(-)}, grad, output, x, y) = @. (grad * one(x),   grad *-one(y))\n",
    "gradient(::Broadcasted{typeof(*)}, grad, output, x, y) = @. (grad * y,        grad * x)\n",
    "gradient(::Broadcasted{typeof(/)}, grad, output, x, y) = @. (grad * one(x)/y, grad *-x/y/y)\n",
    "gradient(::Broadcasted{typeof(abs)}, grad, output, x)  = @. (grad * sign(x), )\n",
    "gradient(::Broadcasted{typeof(sin)}, grad, output, x)  = @. (grad *  cos(x),  )\n",
    "gradient(::Broadcasted{typeof(cos)}, grad, output, x)  = @. (grad * -sin(x), )\n",
    "gradient(::Broadcasted{typeof(tan)}, grad, output, x)  = @. (grad * (tan(x)^2 + 1), )\n",
    "gradient(::Broadcasted{typeof(exp)}, grad, output, x)  = @. (grad *  exp(x), )\n",
    "gradient(::Broadcasted{typeof(sqrt)}, grad, output, x) = @. (grad *.5/sqrt(x), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0194527556569426"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(5.0)\n",
    "y = Variable(4.0)\n",
    "z = sin(y*x)\n",
    "backward(z)\n",
    "u = cos(y*x)\n",
    "backward(u)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jacobian_reverse (generic function with 2 methods)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_reverse = function jacobian_reverse(f, args::Vector{T}) where {T <:Number} \n",
    "    jacobian_rows = Matrix{T}[]\n",
    "    jacobian = Matrix{T}[]\n",
    "    for j=1:length(f)\n",
    "        variables =[]\n",
    "        for i=1:length(args)\n",
    "            var = Variable(args[i])\n",
    "            push!(variables, var)\n",
    "        end\n",
    "        backward(f[j](variables))\n",
    "        grad = Float64[]\n",
    "        for i=1:length(variables)\n",
    "            x = variables[i]\n",
    "            push!(grad,x.grad)   \n",
    "        end\n",
    "        push!(jacobian_rows, grad[:,:])\n",
    "    end\n",
    "    jacobian = hcat(jacobian_rows...)\n",
    "    transpose(jacobian)\n",
    "    \n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coolFunction (generic function with 1 method)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function coolFunction(x::Vector)\n",
    "    z = 1\n",
    "    d = 1\n",
    "    for i = 1 : length(x)\n",
    "        z = z * x[i]\n",
    "        d = d * sin(x[i])\n",
    "    end\n",
    "    return z\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1048037693811945e-44"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coolFunction(rand(Float64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g (generic function with 1 method)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x::Vector)=sin(x[1])\n",
    "g(x::Vector)=cos(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Function}:\n",
       " f (generic function with 2 methods)\n",
       " g (generic function with 1 method)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [f,g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.4050590962409182"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = rand(Float64,(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×100 Matrix{Float64}:\n",
       " 2.67704e-47  2.84505e-46  2.54445e-47  …  8.45747e-47  2.09452e-47\n",
       " 9.34892e-50  1.13444e-48  8.74609e-50     3.33461e-49  6.62346e-50"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian_forward(coolFunction, rand(Float64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×100 Matrix{Float64}:\n",
       " 0.989268  0.0       0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0       0.911739  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian_forward(fun, rand(Float64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching *(::Int64, ::Variable{Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  *(::Any, ::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any...\u001b[39m) at operators.jl:560\n\u001b[0m  *(::T, \u001b[91m::T\u001b[39m) where T<:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:88\n\u001b[0m  *(::Number, \u001b[91m::Union{SparseArrays.SparseVector{Tv, Ti}, SubArray{Tv, 1, var\"#s832\", Tuple{Base.Slice{Base.OneTo{Int64}}}, false} where var\"#s832\"<:SparseArrays.AbstractSparseVector{Tv, Ti}, SubArray{Tv, 1, var\"#s832\", Tuple{Base.Slice{Base.OneTo{Int64}}, Int64}, false} where var\"#s832\"<:SparseArrays.AbstractSparseMatrixCSC{Tv, Ti}} where {Tv, Ti}\u001b[39m) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\SparseArrays\\src\\sparsevector.jl:1449\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching *(::Int64, ::Variable{Float64})\n\u001b[0mClosest candidates are:\n\u001b[0m  *(::Any, ::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any...\u001b[39m) at operators.jl:560\n\u001b[0m  *(::T, \u001b[91m::T\u001b[39m) where T<:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:88\n\u001b[0m  *(::Number, \u001b[91m::Union{SparseArrays.SparseVector{Tv, Ti}, SubArray{Tv, 1, var\"#s832\", Tuple{Base.Slice{Base.OneTo{Int64}}}, false} where var\"#s832\"<:SparseArrays.AbstractSparseVector{Tv, Ti}, SubArray{Tv, 1, var\"#s832\", Tuple{Base.Slice{Base.OneTo{Int64}}, Int64}, false} where var\"#s832\"<:SparseArrays.AbstractSparseMatrixCSC{Tv, Ti}} where {Tv, Ti}\u001b[39m) at C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\SparseArrays\\src\\sparsevector.jl:1449\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] coolFunction(x::Vector{Any})",
      "   @ Main .\\In[138]:5",
      " [2] jacobian_reverse(f::Vector{typeof(coolFunction)}, args::Vector{Float64})",
      "   @ Main .\\In[99]:10",
      " [3] top-level scope",
      "   @ In[139]:1",
      " [4] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [5] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "jacobian_reverse([coolFunction],rand(Float64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  483.00 KiB\n",
       "  allocs estimate:  1711\n",
       "  --------------\n",
       "  minimum time:     731.900 μs (0.00% GC)\n",
       "  median time:      1.040 ms (0.00% GC)\n",
       "  mean time:        1.463 ms (7.08% GC)\n",
       "  maximum time:     18.047 ms (95.41% GC)\n",
       "  --------------\n",
       "  samples:          3357\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@benchmark jacobian_forward(coolFunction, rand(Float64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  481.44 KiB\n",
       "  allocs estimate:  1611\n",
       "  --------------\n",
       "  minimum time:     380.800 μs (0.00% GC)\n",
       "  median time:      563.050 μs (0.00% GC)\n",
       "  mean time:        859.083 μs (12.01% GC)\n",
       "  maximum time:     17.907 ms (97.40% GC)\n",
       "  --------------\n",
       "  samples:          5680\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark jacobian_forward(fun, rand(Float64, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ftmax (generic function with 2 methods)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ftmax(x)\n",
    "    result =[]\n",
    "    sum=0\n",
    "    for i=1:length(x)\n",
    "        sum=sum+exp(x[i])\n",
    "        println(sum)\n",
    "    end\n",
    "    for j=1:length(x)\n",
    "        push!(result,exp(x[j])/sum)\n",
    "    end\n",
    "    result\n",
    "end\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.38905609893065\n",
      "27.47459302211832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 0.2689414213699951\n",
       " 0.7310585786300048"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftmax([2.0,3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU (generic function with 1 method)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU(x) = x > zero(x) ? abs(x) : zero(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Variable(-3.0)\n",
    "backward(ReLU(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching (::Colon)(::Int64, ::CachedNode{ComputableNode{Method{typeof(length)}, Tuple{Variable{Float64}}, NamedTuple{(), Tuple{}}}, Int64})\n\u001b[0mClosest candidates are:\n\u001b[0m  (::Colon)(::T, ::Any, \u001b[91m::T\u001b[39m) where T<:Real at range.jl:41\n\u001b[0m  (::Colon)(::A, ::Any, \u001b[91m::C\u001b[39m) where {A<:Real, C<:Real} at range.jl:10\n\u001b[0m  (::Colon)(::T, ::Any, \u001b[91m::T\u001b[39m) where T at range.jl:40\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching (::Colon)(::Int64, ::CachedNode{ComputableNode{Method{typeof(length)}, Tuple{Variable{Float64}}, NamedTuple{(), Tuple{}}}, Int64})\n\u001b[0mClosest candidates are:\n\u001b[0m  (::Colon)(::T, ::Any, \u001b[91m::T\u001b[39m) where T<:Real at range.jl:41\n\u001b[0m  (::Colon)(::A, ::Any, \u001b[91m::C\u001b[39m) where {A<:Real, C<:Real} at range.jl:10\n\u001b[0m  (::Colon)(::T, ::Any, \u001b[91m::T\u001b[39m) where T at range.jl:40\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] ftmax(x::Variable{Float64})",
      "   @ Main .\\In[106]:4",
      " [2] top-level scope",
      "   @ In[110]:2",
      " [3] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "r = Variable(22.0)\n",
    "backward(ftmax(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
